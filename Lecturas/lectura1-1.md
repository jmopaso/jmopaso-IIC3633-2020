# Crítica: Item-Based Collaborative Filtering Recommendation Algorithms

En este *paper* se hace un repaso de los aspectos más importantes de los sistemas recomendadores basados en filtrado colaborativo. A lo largo del documento, se contrastan dos implementaciones de algoritmos, estas son: *user-based Collaborative Filtering (UBCF)* e *item-based Collaborative Filtering (IBCF)*, cuya discusión es motivada a partir de dos problemas comunes en la actualidad con respecto a los sitemas recomendadores (usualmente implementados con UBCF), los que son la calidad de la predicción (*sparsity*) y la escalabilidad de esta (*scability*). El estudio tiene como hipótesis que los algoritmos IBCF proveen mejores predicciones que UBCF, lo que aumentaría la calidad de la predicción, y además se llevaría a cabo con modelos más pequeños, lo que mejoraría la escalabilidad. 

Creo que el *paper* expone aspectos bastante interesantes, como las formas de obtener similaridad o los cálculos de predicción en los distintos algoritmos, pero el tema que más me llamó la atención fue la explicación de porque se logra una mejor escalabilidad con IBCF. Se ahonda arto en los aspectos técnicos que afectan al rendimiento del algoritmo, donde se hace un contraste con la implementación UBCF. En esta se señala que para hacer la predicción es necesario pasar por un proceso de cálculo de vecinos más cercanos, lo que es sumamente costoso de realizar, sobre todo en un mundo donde los usuarios van en aumento. Sin embargo, para el caso de IBCF, no es necesario hacer esto, ya que se calcula directamente la similaridad item-item. 

También con IBCF no se toman en cuenta todos los items para hacer la predicción, sino que se construye un modelo con los $k$ items más similares, lo que es sumamente relevante ya que si ocuparamos todos los items $n$ se tendría una complejidad de memoria de $O(n^2)$, sin embargo al considerar sólo $k$ con $k < n$ obtenemos una complejidad de $O(k \cdot n)$, que es de alguna forma la explicación de porque mejora la escalabilidad. Si bien, esto último no se señala explicitamente en el *paper*, es algo que se puede deducir de la lectura gracias a los buenos antecedentes que se exponen.

Aún así hay ciertos aspectos de la lectura que creo se pueden mejorar, o quizá no se les abordó con el suficiente detalle que yo hubiese querido. Uno de estos temas es que sentí que no se da un buen análisis de porque UBCF era tan popular en esa época, a pesar de sus deficiencias en términos de calidad de predicción y rendimiento. Sin duda, me da la impresión de que la popularidad de UBCF bajó luego del 2007 (año en que fue publicado este *paper*), pero me hubiese gustado saber las razones de porque era preferido en ese tiempo, cosa de conocer las cualidades de este algoritmo y no sólo sus defectos.

En la misma linea de lo anterior, creo que se le debe dar más importancia al *dataset* utilizado, no sólo para las pruebas realizadas en el estudio, sino que en la discusión en general. Como todo algoritmo de predicción, una buena implementación dependerá en la mayoría de los casos del *dataset*. Dicho esto, creo que en este caso se le dio mucha importancia al algoritmo en si, más allá del ambiente en el cual es implementado. Entiendo que el estudio era sobre el algoritmo, pero creo que hubiese sido bueno que hayan puesto mayor enfasís en esto en la sección de *discusión*.